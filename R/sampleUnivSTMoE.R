sampleUnivST <- function(mu, sigma, nu, lambda, n = 1) {

  e <- sampleUnivSN(0, 1, lambda, n = 1)

  # A gamma variable
  w <- stats::rgamma(n = 1, shape = nu / 2, scale = 2 / nu) # chi2rnd(nu, n, 1) / nu

  # A skew-t variable
  y <- mu + sigma * e/ sqrt(w)

  return(y)
}

#' Draw a sample from a univariate skew-t mixture.
#'
#' @param alphak The parameters of the gating network. `alphak` is a matrix of
#'   size \emph{(q + 1, K - 1)}, with \emph{K - 1}, the number of regressors
#'   (experts) and \emph{q} the order of the logistic regression
#' @param betak Matrix of size \emph{(p + 1, K)} representing the regression
#'   coefficients of the experts network.
#' @param sigmak Vector of length \emph{K} giving the standard deviations of
#'   the experts network.
#' @param lambdak Vector of length \emph{K} giving the skewness parameter of
#'   each experts.
#' @param nuk Vector of length \emph{K} giving the degrees of freedom of the
#'   experts network t densities.
#' @param x A vector og length \emph{n} representing the inputs (predictors).
#'
#' @return A list with the output variable `y` and statistics.
#' \itemize{
#'   \item y Vector of length \emph{n} giving the output variable.
#'   \item zi A vector of size \emph{n} giving the hidden label of the
#'     expert component generating the i-th observation. Its elements are
#'     \eqn{zi[i] = k}, if the i-th observation has been generated by the
#'     k-th expert.
#'   \item z A matrix of size \emph{(n, K)} giving the values of the binary
#'     latent component indicators \eqn{Z_{ik}}{Zik} such that
#'     \eqn{Z_{ik} = 1}{Zik = 1} iff \eqn{Z_{i} = k}{Zi = k}.
#'  \item stats A list whose elements are:
#'    \itemize{
#'      \item Ey_k Matrix of size \emph{(n, K)} giving the conditional
#'        expectation of Yi the output variable given the value of the
#'        hidden label of the expert component generating the ith observation
#'        \emph{zi = k}, and the value of predictor \emph{X = xi}.
#'      \item Ey Vector of length \emph{n} giving the conditional expectation
#'        of Yi given the value of predictor \emph{X = xi}.
#'      \item Vary_k Vector of length \emph{k} representing the conditional
#'        variance of Yi given \emph{zi = k}, and \emph{X = xi}.
#'      \item Vary Vector of length \emph{n} giving the conditional expectation
#'        of Yi given \emph{X = xi}.
#'    }
#' }
#' @export
sampleUnivSTMoE <- function(alphak, betak, sigmak, lambdak, nuk, x) {

  n <- length(x)

  p <- nrow(betak) - 1
  q <- nrow(alphak) - 1
  K = ncol(betak)

  # Build the regression design matrices
  XBeta <- designmatrix(x, p, q)$XBeta # for the polynomial regression
  XAlpha <- designmatrix(x, p, q)$Xw # for the logistic regression

  y <- zeros(n, 1)
  z <- zeros(n, K)
  zi <- rep.int(x = 0, times = K)

  deltak <- lambdak / sqrt(1 + lambdak ^ 2)

  # Calculate the mixing proportions piik:
  piik <- multinomialLogit(alphak, XAlpha, zeros(n, K), ones(n, 1))$piik

  for (i in 1:n) {
    zik <- stats::rmultinom(n = 1, size = 1, piik[i, ])

    mu <- as.numeric(XBeta[i, ] %*% betak[, zik == 1])
    sigma <- sigmak[zik == 1]
    lambda <- lambdak[zik == 1]
    nu <- nuk[zik == 1]

    y[i] <- sampleUnivST(mu = mu, sigma = sigma, nu = nu, lambda = lambda)
    z[i,] <- t(zik)
    zi[i] <- which.max(zik)

  }

  # Statistics (means, variances)
  Xi_nuk = sqrt(nuk / pi) * (gamma(nuk / 2 - 1 / 2)) / (gamma(nuk / 2))
  # E[yi|xi,zi=k]
  Ey_k <- XBeta %*% betak + ones(n, 1) %*% (sigmak * deltak * Xi_nuk)
  # E[yi|xi]
  Ey <- rowSums(piik * Ey_k)

  # Var[yi|xi,zi=k]
  Vary_k <- (nuk / (nuk - 2) - (deltak ^ 2) * (Xi_nuk ^ 2)) * (sigmak ^ 2)
  # Var[yi|xi]
  Vary <- rowSums(piik * (Ey_k ^ 2 + ones(n, 1) %*% Vary_k)) - Ey ^ 2

  stats <- list()
  stats$Ey_k <- Ey_k
  stats$Ey <- Ey
  stats$Vary_k <- Vary_k
  stats$Vary <- Vary

  return(list(y = y, zi = zi, z = z, stats = stats))
}
